{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms, STFT and Griffin-Lim Phase Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "This notebook is an interactive assignment; please read and follow the instructions in each cell.\n",
    "\n",
    "Assignments are to be completed individually.\n",
    "\n",
    "Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "After completing the assignment, please submit this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing Sound Using Spectrograms\n",
    "\n",
    "For this portion of the assignment, you will have the chance to see your own voice!\n",
    "First, make two recordings of yourself:\n",
    "\n",
    "In the first recording, you will say a vowel sound of your choice (\"ah\", \"ee\", \"oo\", etc.). Try to keep the sound short (no longer than you would make the vowel sound in a typical word (\"car\", \"see\", \"good\"). \n",
    "\n",
    "In the second recording, sing (or play on an instrument) any major scale, at a tempo of 60 bpm. (Don't worry, it doesn't need to be perfect- your best effort will be great!). \n",
    "\n",
    "Make sure both of your recordings are saved as mono WAV files. Audacity is a great tool to quickly convert audio file formats (and convert from stereo to mono). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi as midi21\n",
    "from music21 import stream\n",
    "import copy\n",
    "import music21\n",
    "import soundfile as sf\n",
    "from __future__ import  division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import IPython.display as ipydisplay\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the line below with your WAV file:\n",
    "sample_rate, input_signal = wavfile.read(\"PATH_TO_YOUR_VOWEL_MONO_WAV_FILE.wav\")\n",
    "time_array = np.arange(0, len(input_signal)/sample_rate, 1/sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Ah vowel sound', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(time_array[0:4000], input_signal[0:4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 [10 points]\n",
    "\n",
    "The FFT of your input signal is complex valued (real and imaginary components). \n",
    "To visualize the output of the FFT of your input signal, we will calculate the magnitude of the FFT output.\n",
    "In your code, you may want to make use of the .real and .imag members of the numpy complex128 class as you explore the fft_out datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_out = np.fft.rfft(input_signal)\n",
    "\n",
    "fft_mag = ''' Your Code Here'''\n",
    "\n",
    "num_samples = len(input_signal)\n",
    "rfreqs = [(i*1.0/num_samples)*sample_rate for i in range(num_samples//2+1)]\n",
    "setup_graph(title='FFT of Vowel (first 5000)', x_label='FFT Bins', y_label='magnitude', fig_size=(14,7))\n",
    "_ = plt.plot(rfreqs[0:5000], fft_mag[0:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 [10 points]\n",
    "\n",
    "Would you expect another person's recording of the same vowel sound (on the same pitch and at the same volume) to have a similar FFT graph? What musical term is used to describe this quality? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram (FFT over time)\n",
    "\n",
    "### Axes\n",
    "\n",
    "* x-axis: time\n",
    "* y-axis: frequency\n",
    "* z-axis (color): strength of each frequency\n",
    "\n",
    "### See the Harmonics!\n",
    "\n",
    "##### Question 4 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the line below:\n",
    "sample_rate, sample = wavfile.read(\"YOUR_SCALE_MONO_WAV_FILE.wav\")\n",
    "\n",
    "setup_graph(title='Spectrogram of diatonic scale (%dHz sample rate)' % sample_rate, x_label='time (in seconds)', y_label='frequency', fig_size=(14,8))\n",
    "_ = plt.specgram(sample, Fs=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_8000hz = [sample[i] for i in range(0, len(sample), sample_rate//8000)]\n",
    "setup_graph(title='Spectrogram (8000Hz sample rate)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(sample_8000hz, Fs=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_4000hz = [sample[i] for i in range(0, len(sample), sample_rate//4000)]\n",
    "setup_graph(title='Spectrogram (4000Hz sample rate)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(sample_4000hz, Fs=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your recording, you were singing (or playing) a single note at a time. Does this still appear to be the case when looking at the spectrogram of your recording? What are you observing? \n",
    "\n",
    "What would you expect the relationship between the first and last note on your spectrogram to be? Is this the case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 [10 points]\n",
    "\n",
    "Note that the way naive resampling method is done above is theoretically incorrect. Can you explain why? Read about the resampling method in other signal processing libraries such as librosa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 [20 points]\n",
    "\n",
    "Do another 1000 Hz resampling twice: once using the naive method above and second time using a proper downsampling. Plot both spectrograms. Can you detect a difference? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram inversion from spectral amplitude\n",
    "\n",
    "Short-time Fourier Transform (STFT) analysis takes short snapshots of sound and represents them as a matrix of fft vectors.\n",
    "As we saw above, the fft is a complex transform that contain information about amplitude and phase of each frequency component. In many applications we choose to discard the phases and use the amplitudes only. \n",
    "\n",
    "One challenge is to reconstruct the original waveform from amplitude information only.\n",
    "\n",
    "For these questions, we will explore an iterative method by Griffin and Lim.\n",
    "\n",
    "Let's start with creating spectral amplitudes of your earlier vowel WAV file:\n",
    "\n",
    "##### Question 7 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads wav file and produces spectrum\n",
    "# Fourier phases are ignored\n",
    "\n",
    "def wave_to_spectum(x, n_fft):\n",
    "    S = librosa.stft(x, n_fft = n_fft)\n",
    "    p = np.angle(S)   \n",
    "    A = np.log1p(np.abs(S))  \n",
    "    return A\n",
    "\n",
    "### Replace the string below with your file:\n",
    "filename = 'YOUR_WAV_FILE_HERE'\n",
    "x, fs = librosa.load(filename)\n",
    "n_fft = 2048\n",
    "plt.plot(x)\n",
    "SA = wave_to_spectum(x, n_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay.Audio(data=x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(SA[:400,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Griffin and Lim method\n",
    "\n",
    "In the next code block, you will implement the Griffin and Lim iterative method for phase reconstruction.\n",
    "Please look over the pseudocode available on pg. 1865 of Wakabayashi & Ono's 2019 paper, available at http://www.apsipa.org/proceedings/2019/pdfs/290.pdf\n",
    "\n",
    "The random phase initialization is provided as p. Please use 1000 iterations for your reconstruction. \n",
    "\n",
    "You may find the librosa functions istft and stft helpful in your implementation. \n",
    "\n",
    "##### Question 8 [30 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spectrum_wav(a, N_FFT):\n",
    "    # Given input amplitude a, return reconstructed signal x using the Griffin & Lim iterative method.\n",
    "    a = np.exp(a)-1\n",
    "    p = 2 * np.pi * np.random.random_sample(a.shape) - np.pi\n",
    "    '''\n",
    "    YOUR IMPLEMENTATION HERE\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "x_out = write_spectrum_wav(SA, n_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare your reconstruction to the original signal, both auditorily and visually: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = 'out.wav'\n",
    "sf.write(OUTPUT_FILENAME, x_out, fs)\n",
    "display(Audio(OUTPUT_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:1000])\n",
    "plt.plot(x_out[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Griffin and Lim method is not a perfect reconstruction.\n",
    "Let's compare this to directly inverting the complex specta from STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.stft(x, n_fft = n_fft)\n",
    "x_inv = librosa.istft(S, win_length=n_fft)\n",
    "plt.plot(x[:1000])\n",
    "plt.plot(x_inv[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9 [5 points]\n",
    "\n",
    "Describe the difference between the Griffith & Lim and the perfect reconstruction. Does it sound similar? Can you see the difference in the waveform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

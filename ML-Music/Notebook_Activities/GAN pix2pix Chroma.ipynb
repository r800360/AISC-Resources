{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9\n",
    "\n",
    "### GAN, chroma (MIDI) and pix2pix\n",
    "\n",
    "Instructions: \n",
    "\n",
    "* This notebook is an interactive assignment; please read and follow the instructions in each cell. \n",
    "\n",
    "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "* After completing the assignment, please submit this notebook and printout as a PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore a style transfer application that tries to change the musical texture of a piece while maintaining the harmonic structure. In order to do so we train a pix2pix type of model that learns the relations between chroma and the musical texture (distribution of notes). For this purpose we extract chroma from MIDI data and learn a generator that complements the notes from a given texture. You can think about this as something similar to pix2pix that learns completion of image textures from a sketch that was mentioned in class. In the image GAN the contours for training are generated using an edge detection on a complete image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXqiXvjmGkVv"
   },
   "source": [
    "# 1. Imports and Loading Data\n",
    "Before running, please make sure to upload the following to your python directory\n",
    "- reverse_pianoroll.py\n",
    "- convert.py\n",
    "- Classical_Music_Midi.zip and unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zR2xjd5_8g2N"
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import reverse_pianoroll\n",
    "import convert\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LNiQvohD8g25"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SWV1ONBqEj1t"
   },
   "outputs": [],
   "source": [
    "#all necessary imports: use pip install [library name] to add to environment\n",
    "#this notebook was run in 2019 with tensorflow version 1.15. some functions may or may not work with tensorflow > 2.0\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from os import listdir\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t0MVvlIeEj1v"
   },
   "outputs": [],
   "source": [
    "#add songs to data\n",
    "def get_songs(path):\n",
    "    files = glob.glob('{}/*.mid*'.format(path))\n",
    "    songs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            data = pretty_midi.PrettyMIDI(f)\n",
    "            song = data.get_piano_roll(fs=16)\n",
    "            song = convert.forward(song)\n",
    "            # song = np.transpose(song) #if your code matrices aren't working, try uncommenting this. the convert.py file might not be updated\n",
    "            songs.append(song)\n",
    "        except Exception as e:\n",
    "            raise e           \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4MYRJza_Ej1v"
   },
   "outputs": [],
   "source": [
    "#custom function to extract chroma features from song\n",
    "def get_chromas(songs):\n",
    "    chromas = []\n",
    "    for song in songs: \n",
    "        chroma = np.zeros(shape=(np.shape(song)[0], 12))\n",
    "        for i in np.arange(np.shape(song)[0]): \n",
    "            for j in np.arange(78):\n",
    "                if song[i][j] > 0:\n",
    "                    chroma[i][np.mod(j,12)] += 1\n",
    "        #print(np.shape(chroma))\n",
    "        chromas.append(chroma)\n",
    "                \n",
    "    return chromas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8iihxLXwEj1w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 songs processed\n",
      "21 chromas processed\n"
     ]
    }
   ],
   "source": [
    "songs = get_songs('./chordgan/Classical_Music_Midi/mozart')\n",
    "chromas = get_chromas(songs)\n",
    "print (\"{} songs processed\".format(len(songs)))\n",
    "print (\"{} chromas processed\".format(len(chromas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the song and chroma representations\n",
    "\n",
    "Looking at a random song segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3809, 156)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = songs[0]\n",
    "np.shape(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b6c4470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAJBCAYAAABGcMJJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXAUlEQVR4nO3dXazt533Q+e9vbMcmqaImUxIc2zMJI1NIq77pKC0UMdWYTjJQ1bmYaBypI4vJyBopQEGg4sBFNReRKg0qcDFFstpQS3QSRaGjWIipmxqkzkiQ1G3CNIkbYjWQuHHjoPJSUclNysPFeYBd9+T4nP1y9j5nfT43a6//WmvvZ//X2f76+b+tWWsFAP/FeQ8AgItBEACoBAGATRAAqAQBgE0QAKjOMAgz87aZ+czMPDszj57VzwHgdMxZnIcwM7dV/6z63uq56heqd661Pn3qPwyAU3H7GX3ft1TPrrV+tWpmPlA9WF0xCK+YO9ddveqMhgLAUb/Zv/qXa63f/9LlZxWEe6ovHLn/XPWdX+vJd/WqvnMeOKOhAHDUz60P/YsrLT+rIMwVlv2ubVMz80j1SNVdvfKMhgHAtTqrncrPVfcduX9v9cWjT1hrPbbWurTWunRHd57RMAC4VmcVhF+o7p+ZN83MK6qHqifO6GcBcArOZJPRWuurM/Nnqyer26r3rbU+dRY/C4DTcVb7EFpr/YPqH5zV9wfgdDlTGYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYDqBEGYmftm5h/NzDMz86mZ+cG9/LUz85GZ+ey+fc3pDReAs3KSGcJXq7+01voj1XdV756ZN1ePVk+tte6vntr3Abjgjh2Etdbza61f2l//ZvVMdU/1YPX4ftrj1dtPOEYAboBT2YcwM2+svr36aPX6tdbzdTka1etO42cAcLZOHISZ+brq71V/Ya31b6/jdY/MzNMz8/RXevGkwwDghE4UhJm5o8sx+Km11k/vxV+ambv343dXL1zptWutx9Zal9Zal+7ozpMMA4BTcJKjjKb6ieqZtdaPHnnoierh/fXD1YePPzwAbpTbT/Da767+5+qXZ+YTe9lfrX6k+uDMvKv6fPWOE40QgBvi2EFYa/1/1XyNhx847vcF4Hw4UxmAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2AQBgEoQANgEAYBKEADYBAGAShAA2E7yeQi3hCe/+IlT/55vfcO3nfr3BDhrZggAVIIAwHbwm4xs3gG4zAwBgEoQANgEAYBKEADYBAGAShAA2G7Zw06v9Qzkszjs9HrOfnbY62Vnccb4RXXI7/khvc91873XZggAVIIAwCYIAFQ1a63zHkOvnteu75wHznsYAAfh59aHfnGtdemly80QAKgEAYBNEACoBAGATRAAqAQBgE0QAKgEAYBNEACoBAGATRAAqAQBgE0QAKguyCem/aFv+a2efPITp/o9b5ZPKjqLT5C6WX73Q+UT9Q7H0ff6au/lS/9NXOtzr+ffx9HX3Xb3lZ9jhgBAJQgAbD4gB+DA+IAcAK5KEACoBAGA7UIcdgpncfjtRXXIh5Ie0vtcN997bYYAQCUIAGw2GXEh3GxTa47H+3yxmSEAUAkCAJsgAFDZh3BLXm30uL/TeY/7ULja6eE4i6udnsZYXO0UgKsSBAAqVzvlgjikM1gPeTPQIb3PdXHfa1c7BeCqThyEmbltZj4+M39/33/tzHxkZj67b19z8mECcNZO4yijH6yeqV697z9aPbXW+pGZeXTf/yun8HO4hV3UqXV97c0cF3nMF9VFXmdX25x1kcd9mk40Q5iZe6s/Xf34kcUPVo/vrx+v3n6SnwHAjXHSTUZ/s/qh6t8fWfb6tdbzVfv2dVd64cw8MjNPz8zTX+nFEw4DgJM6dhBm5vuqF9Zav3ic16+1HltrXVprXbqjO487DABOyUn2IXx39f0z86equ6pXz8zfrb40M3evtZ6fmburF05joNfrWg9vO+szAs/j5x/XrXjW9nFc61mjN+LsUs7O9ewzuNYzjm+EsxzLsWcIa633rLXuXWu9sXqo+odrrR+onqge3k97uPrwiUcJwJk7i/MQfqT63pn5bPW9+z4AF5wzlQEOjDOVAbgqQQCgEgQAtoP/gBwO01lcpsClDy6+0zhk81Z+n80QAKgEAYDNYacAB8ZhpwBclSAAUAkCAJvDTjkYN/KKlcc9NNEVVE/uPA8LvdnfPzMEACpBAGC7EIedXvrWu9bHnrzvVL/nzTJV86E0p+tmPIv0In34ys3oIm+mudb39kb8Dkd/xm13P+uwUwC+NkEAoBIEALYLsQ/BpSsAbhyXrgDgqgQBgMqZytzkLvIhh6ftkH7Xl7oZDye+GZkhAFAJAgCbIABQOewU4OA47BSAqxIEACqHnd6SjnsF1ZvlQ2Ou9XWcj9N6v1wF9srOcr2YIQBQCQIAmyAAUDnslAvKfoOTuVm2v3ufz4fDTgG4KkEAoLLJCA7OzbI5ibNjkxEAVyUIAFSCAMDm0hX8J8e95MXVXOs26kP+NLAb7ei6vZ7DPk/jEFHv88VmhgBAJQgAbA47BTgwDjsF4KoEAYBKEADYHHYKXJFDRA+PGQIAlSAAsNlkBFyRTUSHxwwBgEoQANgEAYBKEADYBAGAShAA2Bx2ypnyge6Hwft8azBDAKASBAA2QQCgsg+BM2Z78mHwPt8aTjRDmJmvn5kPzcyvzMwzM/NHZ+a1M/ORmfnsvn3NaQ0WgLNz0k1Gf6v6mbXWH66+tXqmerR6aq11f/XUvg/ABXfsIMzMq6s/Uf1E1Vrrt9da/7p6sHp8P+3x6u0nGyIAN8JJZgh/sPpy9Xdm5uMz8+Mz86rq9Wut56v27etOYZwAnLGTBOH26juqv73W+vbq33Udm4dm5pGZeXpmnv5KL55gGACchpME4bnqubXWR/f9D3U5EF+ambur9u0LV3rxWuuxtdaltdalO7rzBMMA4DQcOwhrrV+vvjAz37gXPVB9unqiengve7j68IlGCMANcdLzEP5c9VMz84rqV6s/0+XIfHBm3lV9vnrHCX8GADfAiYKw1vpEdekKDz1wku8LwI3n0hUAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVCcMwsz8xZn51Mx8cmbePzN3zcxrZ+YjM/PZffua0xosAGfn2EGYmXuqP19dWmt9c3Vb9VD1aPXUWuv+6ql9H4AL7qSbjG6vft/M3F69svpi9WD1+H788ertJ/wZANwAxw7CWuvXqr9efb56vvo3a62frV6/1np+P+f56nWnMVAAztZJNhm9psuzgTdVb6heNTM/cB2vf2Rmnp6Zp7/Si8cdBgCn5CSbjP5k9bm11pfXWl+pfrr6Y9WXZubuqn37wpVevNZ6bK11aa116Y7uPMEwADgNJwnC56vvmplXzsxUD1TPVE9UD+/nPFx9+GRDBOBGuP24L1xrfXRmPlT9UvXV6uPVY9XXVR+cmXd1ORrvOI2BAnC2jh2EqrXWD1c//JLFL3Z5tgDATcSZygBUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABUggDAJggAVIIAwCYIAFSCAMAmCABU1xCEmXnfzLwwM588suy1M/ORmfnsvn3NkcfeMzPPzsxnZuatZzVwAE7XtcwQfrJ620uWPVo9tda6v3pq329m3lw9VH3Tfs2PzcxtpzZaAM7MywZhrfXz1W+8ZPGD1eP768ertx9Z/oG11otrrc9Vz1ZvOZ2hAnCWjrsP4fVrreer9u3r9vJ7qi8ced5ze9nvMTOPzMzTM/P0V3rxmMMA4LSc9k7lucKydaUnrrUeW2tdWmtduqM7T3kYAFyv4wbhSzNzd9W+fWEvf66678jz7q2+ePzhAXCjHDcIT1QP768frj58ZPlDM3PnzLypur/62MmGCMCNcPvLPWFm3l99T/UNM/Nc9cPVj1QfnJl3VZ+v3lG11vrUzHyw+nT11erda63fOaOxA3CKXjYIa613fo2HHvgaz39v9d6TDAqAG8+ZygBUggDAJggAVIIAwCYIAFSCAMAmCABU13Aewq3uyS9+4nfdf+sbvu1cxgFw3swQAKgEAYDt4DcZ2UQEcJkZAgCVIACwCQIAlSAAsAkCAJUgALAd/GGnZ8HZz8DNyAwBgEoQANgEAYDKPoQzYZ8BcDMyQwCgEgQANkEAoBIEADZBAKASBAA2QQCgEgQANkEAoBIEADZBAKASBAA2QQCguiBXO/1D3/JbPfnkJ6rDu1Lo0U9XO7TfHW511/r3fT2fsniW/80wQwCgEgQAtllrnfcYevW8dn3nPHDewwA4CD+3PvSLa61LL11uhgBAJQgAbIIAQCUIAGyCAEAlCABsggBAJQgAbIIAQCUIAGwX4mqn5+l6rjJ4s3AFVbgYzuJqp2fJDAGAShAA2FztFODAuNopAFclCABUjjKCl+WorcPgfTZDAGATBAAqQQBgsw/hDFyUsw45Hd6/w3CzvM9nua/jZWcIM/O+mXlhZj55ZNn/MTO/MjP//8z83zPz9Ucee8/MPDszn5mZt57qaAE4M9eyyegnq7e9ZNlHqm9ea31L9c+q91TNzJurh6pv2q/5sZm57dRGC8CZedlNRmutn5+ZN75k2c8euftPqv9xf/1g9YG11ovV52bm2eot1T8+neHeHG6WqSdw8znL/76cxk7l/6X6f/bX91RfOPLYc3sZABfciXYqz8xfq75a/dR/XHSFp13xYkkz80j1SNVdvfIkwwDgFBw7CDPzcPV91QPrP18h77nqviNPu7f64pVev9Z6rHqsLl/c7rjjAOB0HCsIM/O26q9U/+1a67eOPPRE9X/NzI9Wb6jurz524lHCKTuLQ4Nd+uAw3MqHlb9sEGbm/dX3VN8wM89VP9zlo4rurD4yM1X/ZK31v621PjUzH6w+3eVNSe9ea/3OWQ0egNNzLUcZvfMKi3/iKs9/b/XekwwKgBvPB+QAHBgfkAPAVQkCAJUgALC52imcgeMemngrH9J4ozj89/jMEACoBAGA7UIcdnrpW+9aH3vy8hUvDm2KZ3p7um7G9Xkzjplrc63v7Y3eVOiwUwCuShAAqAQBgO1C7ENw6QqAG8c+BACuShAAqJypDDeNQz6L+ZB/9xvJDAGAShAA2AQBgMo+BLhpHPJ280P+3W8kMwQAKkEAYLPJ6BZ0Ua+e6UNjDoP362yd5d+3GQIAlSAAsAkCAJWrncIt6aLuR3qpm2WctxpXOwXgqgQBgMphp3BLulk2v9ws4zwUZggAVIIAwCYIAFT2IcBBu57LTDhE9NZnhgBAJQgAbDYZwQG7nk0/NhPd+swQAKgEAYBNEACoBAGATRAAqAQBgE0QAKgEAYBNEACoBAGATRAAqAQBgE0QAKgEAYBNEACoBAGATRAAqAQBgE0QAKgEAYBNEACoBAGATRAAqAQBgE0QAKiuIQgz876ZeWFmPnmFx/7yzKyZ+YYjy94zM8/OzGdm5q2nPWAAzsa1zBB+snrbSxfOzH3V91afP7LszdVD1Tft1/zYzNx2KiMF4Ey9bBDWWj9f/cYVHvob1Q9V68iyB6sPrLVeXGt9rnq2estpDBSAs3WsfQgz8/3Vr621/ulLHrqn+sKR+8/tZQBccLdf7wtm5pXVX6v++ys9fIVl6wrLmplHqkeq7uqV1zsMAE7ZcWYI/031puqfzsw/r+6tfmlm/kCXZwT3HXnuvdUXr/RN1lqPrbUurbUu3dGdxxgGAKfpuoOw1vrltdbr1lpvXGu9scsR+I611q9XT1QPzcydM/Om6v7qY6c6YgDOxLUcdvr+6h9X3zgzz83Mu77Wc9dan6o+WH26+pnq3Wut3zmtwQJwdl52H8Ja650v8/gbX3L/vdV7TzYsAG40ZyoDUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUAkCAJsgAFAJAgCbIABQCQIAmyAAUNWstc57DM3Ml6t/UX1D9S/PeTgXkfXye1knV2a9XJn18rv912ut3//ShRciCP/RzDy91rp03uO4aKyX38s6uTLr5cqsl2tjkxEAlSAAsF20IDx23gO4oKyX38s6uTLr5cqsl2twofYhAHB+LtoMAYBzcmGCMDNvm5nPzMyzM/PoeY/nPMzMfTPzj2bmmZn51Mz84F7+2pn5yMx8dt++5rzHeh5m5raZ+fjM/P19/+DXy8x8/cx8aGZ+Zf+7+aOHvl5m5i/uv59Pzsz7Z+auQ18n1+pCBGFmbqv+z+p/qN5cvXNm3ny+ozoXX63+0lrrj1TfVb17r4dHq6fWWvdXT+37h+gHq2eO3Lde6m9VP7PW+sPVt3Z5/RzsepmZe6o/X11aa31zdVv1UAe8Tq7HhQhC9Zbq2bXWr661frv6QPXgOY/phltrPb/W+qX99W92+Y/7ni6vi8f30x6v3n4uAzxHM3Nv9aerHz+y+KDXy8y8uvoT1U9UrbV+e631rzvw9VLdXv2+mbm9emX1xayTa3JRgnBP9YUj95/byw7WzLyx+vbqo9Xr11rP1+VoVK87x6Gdl79Z/VD1748sO/T18gerL1d/Z29K+/GZeVUHvF7WWr9W/fXq89Xz1b9Za/1sB7xOrsdFCcJcYdnBHv40M19X/b3qL6y1/u15j+e8zcz3VS+stX7xvMdywdxefUf1t9da3179uw58U8jeN/Bg9abqDdWrZuYHzndUN4+LEoTnqvuO3L+3y9O8gzMzd3Q5Bj+11vrpvfhLM3P3fvzu6oXzGt85+e7q+2fmn3d5c+J/NzN/N+vlueq5tdZH9/0PdTkQh7xe/mT1ubXWl9daX6l+uvpjHfY6uWYXJQi/UN0/M2+amVd0eSfQE+c8phtuZqbL24OfWWv96JGHnqge3l8/XH34Ro/tPK213rPWunet9cYu/9v4h2utH8h6+fXqCzPzjXvRA9WnO+z18vnqu2bmlfvv6YEu74s75HVyzS7MiWkz86e6vJ34tup9a633nu+IbryZ+ePV/1v9cv95W/lf7fJ+hA9W/1WX/8G/Y631G+cyyHM2M99T/eW11vfNzH/Zga+Xmfm2Lu9of0X1q9Wf6fL/6B3sepmZ/736n7p81N7Hq/+1+roOeJ1cqwsTBADO10XZZATAORMEACpBAGATBAAqQQBgEwQAKkEAYBMEAKr6D95K6hgXT4NRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(100*song[:100,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3809, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma = chromas[0]\n",
    "np.shape(chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18880e6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(100*chroma[:100,:].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 [10 points]\n",
    "Describe what the chromas function does. In your answer refer to musical terms of note names and octave numbers. How does that resemble or differ from the chroma feature that is computed for audio spectrum? Use the figures to demonstrate the explanation.\n",
    "\n",
    "Hint: Refresh the musical terms by looking at Slides 1 and consider what type of music anaylsis the audio chroma is used for. If you are interested more in musical theory you may also consider the concepts of \"pitch class\" and \"music set theory\" that are explained in https://en.wikipedia.org/wiki/Musical_note and https://en.wikipedia.org/wiki/Set_theory_%28music%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIhhTSj6GtvT"
   },
   "source": [
    "# 2. Setting Up GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIaKKrWmEj1w",
    "outputId": "5bd4c581-204f-4706-a2a6-c9edfde2e467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 48\n"
     ]
    }
   ],
   "source": [
    "lowest_note = 0 #the index of the lowest note on the piano roll\n",
    "highest_note = 78 #the index of the highest note on the piano roll\n",
    "note_range = highest_note-lowest_note #the note range\n",
    "\n",
    "num_timesteps  = 4 #This is the number of timesteps that we will create at a time\n",
    "X_dim = 2*note_range*num_timesteps #This is the size of the visible layer. \n",
    "Z_dim = 12*num_timesteps\n",
    "n_hidden = 50 #This is the size of the hidden layer\n",
    "\n",
    "print(X_dim,Z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 [10 points]\n",
    "\n",
    "Explain what aspects of music (pitch, rhythm, note duration) are captured by the latent random Z? In your answer refer to the representaiton of the song data. Note how song matrix differs from standard pianoroll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uDpINNjpEj1x"
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "24NXtz5IEj1x"
   },
   "outputs": [],
   "source": [
    "#setting up model, discriminator weights and biases\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([X_dim+Z_dim, 512]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[512]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([512, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LRLHyW-CEj1x"
   },
   "outputs": [],
   "source": [
    "#setting up model, generator weights and biases\n",
    "\n",
    "#z is the space we're generating from\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([Z_dim, 128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([128, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mIjKz4MwEj1x"
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bWImNLv-Ej1y"
   },
   "outputs": [],
   "source": [
    "def discriminator(x,c):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(tf.concat([x,c],1), D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tI8yFjDWEj1y"
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        plt.imshow(sample.reshape(78, 30), cmap='Greys_r')\n",
    "\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "P8CrxuCaEj1z"
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kjJ7f5I-Ej10"
   },
   "outputs": [],
   "source": [
    "D_real, D_logit_real = discriminator(X,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "n8992jJOEj10"
   },
   "outputs": [],
   "source": [
    "D_fake, D_logit_fake = discriminator(G_sample,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 [10 points]\n",
    "In standard GAN, the discriminator receives as input true or fake (generated) data only. Explain why in our case the disrciminator receives as input both the data and an additional variable Z? How this Z differs from the usual GAN input of a random vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tcYoVloPEj10"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Alternative losses:\n",
    "# -------------------\n",
    "Lambda = 100\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "G_loss_L1 = tf.reduce_mean(tf.losses.mean_squared_error(X,G_sample))\n",
    "G_loss = G_loss_fake + Lambda*G_loss_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 [10 points]\n",
    "Explain the two components of the discriminator loss in the D_loss expression. Why the real loss uses tf.ones_like andthe fake loss uses tf.zeros_like in the cross entory loss? What are the statistical distributions (which datasets are used) in computational of the real and fake losses. In your answers you may either include an equation image or write the loss equaiton in latex mathamtical notation inside Markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 [10 points]\n",
    "In the generator loss G_loss we add an L1 loss. What does it represent? Why do you think we might want to add the L1 loss to the GAN model? We will explore this question further down the assignment, so at this point write down your best explanation based on the equations themselves without running any experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Oc9zTKiEEj11"
   },
   "outputs": [],
   "source": [
    "#optimizing functions\n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "V_yjcm__Ej11"
   },
   "outputs": [],
   "source": [
    "#output midi file folder\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wMfONb8gEj11"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI2HBr6YGzkM"
   },
   "source": [
    "# 3. Training GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FZBAHllDEj11",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "num_epochs = 200000\n",
    "batch_size = 100\n",
    "S_cutoff = 0.5\n",
    "#commented out print statements output different losses, and plotting functions plot the piano roll and chroma.\n",
    "while i <= num_epochs:\n",
    "    for song, chroma in zip(songs, chromas):      \n",
    "        # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
    "        # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements    \n",
    "        song = np.array(song)     \n",
    "        #print(np.shape(song))  \n",
    "        song_steps = np.floor(song.shape[0]/num_timesteps).astype(int)\n",
    "        song = song[:song_steps*num_timesteps]\n",
    "        song = np.reshape(song, [song_steps, song.shape[1]*num_timesteps])  \n",
    "        chroma = np.array(chroma)\n",
    "        #print(np.shape(chroma)\n",
    "        chroma = chroma[:song_steps*num_timesteps]\n",
    "        chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])                \n",
    "        batch_size = min(batch_size,len(song))\n",
    "        # Train the RBM on batch_size examples at a time\n",
    "        for ind in range(0, len(song), batch_size):       \n",
    "            X_mb = song[ind:ind+batch_size]\n",
    "            ch = chroma[ind:ind+batch_size]\n",
    "#            _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb})\n",
    "            _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: ch})\n",
    "            _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={X: X_mb, Z: ch})\n",
    "    \n",
    "            if i % 1000 == 0:\n",
    "                # print('Iter: {}'.format(i))\n",
    "                dloss = ('D_Loss: {:.4}'. format(D_loss_curr))\n",
    "                gloss = ('G_Loss: {:.4}'. format(G_loss_curr))\n",
    "                print(dloss)\n",
    "                print(gloss)\n",
    "                \n",
    "#             samples = sess.run(X_samples, feed_dict={z: np.random.randn(1,z_dim)})\n",
    "\n",
    "                samples = sess.run(G_sample, feed_dict={Z: ch})\n",
    "        \n",
    "                S = np.reshape(samples, (ch.shape[0]*num_timesteps, 2*note_range))\n",
    "                thresh_S = S>=S_cutoff\n",
    "\n",
    "                thresh_S = np.transpose(thresh_S)\n",
    "\n",
    "\n",
    "                C = np.reshape(ch, (ch.shape[0]*num_timesteps, 12))\n",
    "\n",
    "                test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
    "                test.write('out/{}.mid'.format(i))\n",
    "\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9svDngpHzty"
   },
   "source": [
    "# 4. Style Transfer with a New Genre Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will explore using the trained GAN to compose new music according to the harmonic structure of another musical input. In a way this comprises of a style transfer between the input music that belongs to style A and the output music that is generated using GAN trained on style B. In the example we will used J.S.Bach as our input (Style A) and output music in Mozart's style that was use to train our GAN (Style B). The new Mozart piece should follow the harmonic structure (chord progressions) of the Bach input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SSzNXQleEj13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 songs processed\n",
      "3 songs processed\n"
     ]
    }
   ],
   "source": [
    "#for testing, we will be using a different composer dataset to input into the generator here.\n",
    "test_song = get_songs(\"./chordgan/Classical_Music_Midi/bach\")\n",
    "test_chromaz = get_chromas(test_song)\n",
    "print (\"{} songs processed\".format(len(test_song)))\n",
    "print (\"{} songs processed\".format(len(test_chromaz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "g-lb4wigiXTm"
   },
   "outputs": [],
   "source": [
    "#converted midi file folder\n",
    "if not os.path.exists('converted/'):\n",
    "    os.makedirs('converted/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "R1yURaYKEj14"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "S_cutoff = 0.5\n",
    "\n",
    "for c in test_chromaz:\n",
    "    test_chroma = np.array(c)\n",
    "    \n",
    "\n",
    "    test_chroma = test_chroma[:np.floor(test_chroma.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
    "    test_chroma = np.reshape(test_chroma, [int(test_chroma.shape[0]/num_timesteps), test_chroma.shape[1]*num_timesteps])\n",
    "    #chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])\n",
    "       \n",
    "    out_samples = sess.run(G_sample, feed_dict={Z: test_chroma})\n",
    "    #print(np.shape(test_chroma),np.shape(samples))\n",
    "    \n",
    "    #print(np.floor(samples.shape[0]*samples.shape[1]/2/note_range).astype(int))\n",
    "    \n",
    "    S = np.reshape(out_samples, (np.floor(out_samples.shape[0]*out_samples.shape[1]/2/note_range).astype(int), 2*note_range))\n",
    "    C = np.reshape(test_chroma, (test_chroma.shape[0]*num_timesteps, 12))\n",
    "    #print(np.shape(S), np.shape(C))\n",
    "    thresh_S = S>=S_cutoff\n",
    "    thresh_S = np.transpose(thresh_S)\n",
    "\n",
    "\n",
    "    \n",
    "    # plt.figure(figsize=(30,18))\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(S)\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(C)\n",
    "    # #plt.tight_layout()\n",
    "    # plt.pause(0.1)\n",
    "\n",
    "\n",
    "    test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
    "    test.write('converted/{}.mid'.format(i))\n",
    "\n",
    "    # midi_manipulation.noteStateMatrixToMidi(thresh_S, \"new/generated_chord_{}\".format(i))\n",
    "    # i+=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 [10 points]\n",
    "Open the conversion results in a musical MIDI software (such as Musescore) and observe/listen to the results. Write down your impressions about the quality of the musical texture style transfer - did the harmonic structure follow the Bach input? How did the notes distribution (choice of pitches and durations) change relative to the original Bach piece? Does the S_cutoff parameter affect the outcome, and if so, how? \n",
    "\n",
    "Summarize your findings and suggest some conclusions. Can you point to any musical aspects that were poorly modeled and ideas of improvement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Further experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 & 8: [total 40 points]\n",
    "\n",
    "Choose two of the experiments and report their results:\n",
    "\n",
    "1. Explore style transfer between more distant styles: For this purpose you may use the Pop_Music_Midi dataset and repeat the Style Transfer Experiment between Classical and Pop music (and vice versa). Report your findings in qualitative ways and submit the midi results together with your explanation. [20 Points]\n",
    "\n",
    "2. Expermment with L1 distance: retrain the GAN model with very small and very large Lambda. What are the effects of such changes? When is the texture of the output more or less musical? Are the harmonic progressions of the input followed or ignored? Any other observations? [20 Points]\n",
    "\n",
    "3. Create your own song: use the leadsheet2chroma.py file provided to create a Mozart style composition from your own leadsheet input. Provide the leadsheet in text format and the midi file results. Report your observations about the musical quality of the results. You may alter the leadsheet2chroma.py to fit other chords if you wish, or train GAN in a style different then Mozart. [20 Points]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GANMIDItest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "\n",
    "### Mozart Dice Game RNN\n",
    "\n",
    "Instructions: \n",
    "\n",
    "* This notebook is an interactive assignment; please read and follow the instructions in each cell. \n",
    "\n",
    "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "* After completing the assignment, please submit this notebook and a copy as a PDF.\n",
    "\n",
    "Please note that managing packages may take some time to set up. \n",
    "If you are using the UCSD Datahub, students have had success using a CPU instance, and installing packages in this order:\n",
    "\n",
    "pip install music21\n",
    "\n",
    "pip install --upgrade pip\n",
    "\n",
    "pip install tensorflow\n",
    "\n",
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Music with RNN\n",
    "\n",
    "In the next section, you will practice using Keras to create a generative model based on the music of your & your classmates' Mozart Dice Game from Assignment 1. \n",
    "\n",
    "You will be constructing an RNN by filling in some missing lines of code & answering questions about Keras and model performance. \n",
    "\n",
    "The overall goal of this model is to be able to predict the next note of a sequence, given a sequence of 4 notes. (This sequence length of 4 was chosen arbitrarily; please feel free to experiment with this number). \n",
    "\n",
    "First, let's define the RNN model we will use. \n",
    "A base LSTM layer has been included below.\n",
    "\n",
    "##### Question 1 (30 points)\n",
    "\n",
    "Define & compile the rest of the network as follows:\n",
    "\n",
    "The additional layers of your network will be:\n",
    "\n",
    "    1. Another LSTM layer, with 512 units of output which drops 3/10 of the units. \n",
    "    2. A batch normalization layer.\n",
    "    3. A layer which drops 3/10 of the units. \n",
    "    4. A fully connected layer with 256 units of output.\n",
    "    5. A ReLU activation layer.\n",
    "    6. A batch normalization layer.\n",
    "    7. A layer which drops 3/10 of the units. \n",
    "    8. A fully connected layer with number of units of output equal to the vocabulary space of the input. \n",
    "    9. A softmax activation layer which uses a temperature parameter. (We have provided this for you -- note that you must define this as two separate `layers' in Keras). \n",
    "    \n",
    "After creating your network, compile the model with categorical cross entropy loss and an optimizer of your choice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from numpy.random import choice\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab, temperature):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    ''' Your Code Here '''\n",
    "\n",
    "\n",
    "    \n",
    "    model.add(Lambda(lambda x: x/temperature))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='CHANGE_ME', optimizer='CHANGE_ME')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to structure our input data in a way that makes sense. We can't pass a direct MIDI file to a network, so we must come up with an encoding. Read the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_all_possible_notes(glob_query):\n",
    "    '''\n",
    "    Cycles through all MIDI files using the given glob_query, collecting every possible note (consisting of pitch and duration) found in each file.\n",
    "    Creates an unordered list of the SET of these notes, dumps them into pickle file notes.p, and returns the list of notes.\n",
    "    '''\n",
    "    notes = OrderedDict()\n",
    "    durations = []\n",
    "    for file in glob.glob(glob_query): \n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                note_str = str(element.duration) + \"-\" + str(element.pitch)\n",
    "                if note_str not in notes:\n",
    "                    notes[note_str] = len(notes) # use len(notes) as the value to ensure that each note has a unique index\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                chord_str = str(element.duration) +\"-\"+ '.'.join(str(n) for n in element.normalOrder)\n",
    "                if chord_str not in notes:\n",
    "                    notes[chord_str] = len(notes)\n",
    "\n",
    "    note_list = list(notes.keys())\n",
    "    pickle.dump(note_list, open('notes.p', 'wb'))\n",
    "\n",
    "    return note_list\n",
    "\n",
    "\n",
    "def get_sequences(glob_query):\n",
    "    '''\n",
    "    Cycles through all MIDI files using the given glob_query, collecting every possible note (consisting of pitch and duration) found in each file.\n",
    "    Creates a list of these notes in their sequence order, and returns this list.\n",
    "    The output sequences are in \"human\" form (i.e. note name, duration)\n",
    "    '''\n",
    "    notes = []\n",
    "    for file in glob.glob(glob_query):\n",
    "        midi = converter.parse(file)\n",
    "        #print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None #notes_to_parse = null value\n",
    "        try: # file has instrument parts #try lets you test a block of code for errors\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.duration) + \"-\" + str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append(str(element.duration) +\"-\"+ '.'.join(str(n) for n in element.normalOrder))\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(sequence): \n",
    "    \"\"\" Prepare the sequences used by the Neural Network.\n",
    "        Note that \"sequence\" is one giant sequence representing all of the input sequences, concatenated together as a \"mega sequence\".\n",
    "        This is something that should be fixed in future iterations, as this will create some instances of \"false transitions\", having the last note of one piece jump to the first note of the next.\n",
    "        It will work as 'ideally' intended only if trained on just one song. We will use this function as-is for the homework, but you are welcome to adjust it if you like.\n",
    "        First, converts the sequences from human-readable form to integer form (i.e. \"note, duration\" is replaced by a numeric index)\n",
    "        Then, converts to a one-hot encoding.\n",
    "        Returns the input sequences and generated output.\n",
    "    \"\"\"\n",
    "    input_sequence_length = 8\n",
    "\n",
    "    # Form \"note_to_int\" lookup dictionary using notes.p, the file where we have stored a list of all the notes that appear in our vocabulary.\n",
    "    pitchnames = pickle.load(open(\"notes.p\", \"rb\"))\n",
    "\n",
    "    #dictionary called note_to_int is created where the keys are the elements of the pitchnames list and the values are their indices obtained using the enumerate() function.\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    n_vocab = len(pitchnames)\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # The for loop iterates over a range of values obtained from the length of the notes list,\n",
    "    # starting from 0 and incrementing by 1 for each iteration, until the last value that is len(notes) - sequence_length.\n",
    "    # The sequence_length is an input parameter that determines the length of the input sequence.\n",
    "    for i in range(0, len(sequence) - input_sequence_length, 1):\n",
    "\n",
    "        # the sequence_in variable is assigned a slice of the notes list from the current index i to i + sequence_length.\n",
    "        sequence_in = sequence[i:i + input_sequence_length]\n",
    "\n",
    "        sequence_out = sequence[i + input_sequence_length]\n",
    "\n",
    "        #appends to the network output to list the numerical value of the corresponding output note sequence_out in the note_to_int dictionary.\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    #returns length of network input\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, input_sequence_length, 1))\n",
    "    network_input = to_categorical(network_input, num_classes = n_vocab)\n",
    "\n",
    "    network_output = to_categorical(network_output, num_classes = n_vocab)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "\n",
    "vocabulary = get_list_of_all_possible_notes(\"dice_songs/*.mid\")\n",
    "sequence = get_sequences(\"dice_songs/*.mid\")\n",
    "network_input, network_output = prepare_sequences(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 (10 points)\n",
    "\n",
    "How is the data from the MIDI file encoded as input to the network? Be specific in your explanation; make sure you address details such as which data type is used to represent a note in the input layer and how chords are handled, as well as what information is lost by using this encoding. \n",
    "\n",
    "[Hint: Try to print some of the variables to visualize their data.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the network.\n",
    "\n",
    "##### Question 3 (10 points)\n",
    "\n",
    "Add a line of code to begin the training of the model.\n",
    "Please train for at least 50 epochs (you are welcome to experiment with the duration of training, batch size, and other hyperparameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    \n",
    "    vocabulary = get_list_of_all_possible_notes(\"dice_songs/*.mid\")\n",
    "\n",
    "    n_vocab = len(set(vocabulary))\n",
    "    \n",
    "    sequence = get_sequences(\"dice_songs/*.mid\")\n",
    "    network_input, network_output = prepare_sequences(sequence)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab, 1)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    \n",
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained network to make predictions, it's time to use the network to generate music!\n",
    "\n",
    "##### Question 4 (10 points)\n",
    "\n",
    "To make the predictions, you will need to complete the line in the generate_notes function below.\n",
    "\n",
    "[Hint: what function does Keras use to make predictions?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_prediction(notes, pitchnames, n_vocab):\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 4\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = to_categorical(np.reshape(network_input, (n_patterns, sequence_length, 1)), num_classes = n_vocab)\n",
    "    # normalize input\n",
    "    \n",
    "    return (network_input, normalized_input)\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = to_categorical(prediction_input, num_classes = n_vocab)\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = ''' Your Code Here'''\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our model set up, and can create a sequence to use as a query for a prediction of the next note, but we aren't ready to make the predictions since our model does not contain the trained weights!\n",
    "\n",
    "##### Question 5 (10 points)\n",
    "\n",
    "Add a line below to load the weights from your network training. \n",
    "\n",
    "[Hint: What Keras function is used to load weights?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab, 1)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern_outer in prediction_output:\n",
    "        pattern = pattern_outer.split(\"-\")[1]\n",
    "        duration = float(pattern_outer.split(\"-\")[0].split(\" \")[1][:-1])\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note), quarterLength=duration)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern, quarterLength =duration)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += duration #0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "    \n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 (10 points)\n",
    "\n",
    "Listen to your MIDI output. You probably notice that at some point we reach a cycle. Why might this be happening? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 (10 points)\n",
    "\n",
    "The generate_notes function is copied below. Please add your same prediction line from above once more, and then modify the generate_notes function in a way that allows for a non-cyclic composition that still resembles the original input. \n",
    "\n",
    "[Hint: think about what we learned in HW 2 while exploring Markov Chains with the Beatles.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = to_categorical(prediction_input, num_classes = n_vocab)\n",
    "\n",
    "        \n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction = ''' Your Code Here'''\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8 (5 points)\n",
    "\n",
    "While we may have improved our ability to avoid getting stuck in cycles, there is more we can do to improve this! \n",
    "Think about your improvement made above. Describe (in general) the probability condition in which the method is least effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your Response Here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9 (5 points)\n",
    "\n",
    "We can use temperature to help this further. Select a temperature parameter to replace the `1' below. Explore different parameters until you notice a difference in performance, then state your selected value and describe the difference (and why it occurs) below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab, 1) # Modify the temperature parameter here!\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)\n",
    "    \n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your Response Here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bonus Question 10 (10 points, but your total will not exceed 100)\n",
    "\n",
    "There are many other ways in which this model could be improved for the goal of creating music that sounds like the training set. Identify two shortcomings of the model performance, and propose an idea you would use to overcome each of the shortcomings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Formants with Linear Predictive Coding, Vocoder (Mister Blue Sky)\n",
    "\n",
    "Instructions: \n",
    "\n",
    "* This notebook is an interactive assignment; please read and follow the instructions in each cell. \n",
    "\n",
    "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "* After completing the assignment, please submit this notebook and its pdf printout and all sound files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Formants and LPC\n",
    "\n",
    "In this section, you will synthesize vowel sounds, and investigate the frequencies in vowels from your own voice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy.random import multinomial as randm\n",
    "from numpy import where\n",
    "import scipy.signal as si\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import scipy\n",
    "import librosa.display as ld\n",
    "import music21\n",
    "from music21 import midi as midi21\n",
    "from music21 import stream\n",
    "from jchord.progressions import ChordProgression, MidiConversionSettings\n",
    "from scipy.io import wavfile as wavfile \n",
    "import copy\n",
    "\n",
    "\n",
    "Fdict = {\n",
    "    'mystery_1':[[328, 2208, 2885],[27,80,575]],\n",
    "    'mystery_2':[[504, 868, 2654],[62,   108,  299]],\n",
    "    'mystery_3':[[700, 1220, 2600],[130,   70,  160]]\n",
    "    } # Formant frequencies in Hz\n",
    "\n",
    "def excitation(f0,jitt,dur,nharm=None,unvoiced=False):\n",
    "    w0T = 2*np.pi*f0/fs\n",
    "\n",
    "    if nharm == None:\n",
    "        nharm = int((fs/2)/f0) # number of harmonics\n",
    "    nsamps = fs*dur\n",
    "    sig = np.zeros(nsamps)\n",
    "    ph = np.random.uniform(size=nsamps)*2*np.pi\n",
    "    n = np.arange(nsamps)\n",
    "\n",
    "    if unvoiced:\n",
    "        sig = np.random.normal(size=nsamps)\n",
    "    else:\n",
    "    # Synthesize bandlimited impulse train\n",
    "        for i in range(1,nharm):\n",
    "            sig = sig + np.cos(i*w0T*n + jitt*ph)\n",
    "    \n",
    "    sig = sig/max(sig)\n",
    "    return sig\n",
    "\n",
    "def voca(sig,F,Fb):\n",
    "    R = np.exp(-np.pi*Fb/fs);     # Pole radii\n",
    "    theta = 2*np.pi*F/fs;     # Pole angles\n",
    "    poles = R * np.exp(1j*theta) # Poles[B,A] = zpk2tf(0,np.concatenate((poles, np.conj(poles))),1) # Filter from zeros and poles\n",
    "    \n",
    "    [B,A] = si.zpk2tf(0,np.concatenate((poles, np.conj(poles))),1) # Filter from zeros and poles\n",
    "\n",
    "    speech = si.lfilter(B, A, sig)\n",
    "    speech = speech/np.std(speech)\n",
    "    return speech,B,A\n",
    "\n",
    "fs = 8192 # 22050  % Sampling rate in Hz (\"telephone quality\" for speed)\n",
    "\n",
    "vowels = list(Fdict.keys())\n",
    "f0 = 150 # Pitch in Hz\n",
    "dur = 1 #one second in duration\n",
    "ji = 0.1 #0.1\n",
    "ex = excitation(f0,ji,dur)\n",
    "\n",
    "text = ['mystery_1','mystery_2','mystery_3']\n",
    "\n",
    "speech = np.zeros(1)\n",
    "for t in text:\n",
    "    F = np.array(Fdict[t][0])\n",
    "    Fb = np.array(Fdict[t][1])\n",
    "    print(t)\n",
    "\n",
    "    vow,B,A = voca(ex,F,Fb)\n",
    "    speech = np.concatenate((speech,vow))\n",
    "\n",
    "speech = speech/np.std(speech)\n",
    "plt.plot(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(speech, rate=fs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 (10 points)\n",
    "\n",
    "Based on the audio output, what vowels were synthesized as mystery_1, mystery_2, and mystery_3? \n",
    "Please specify using a word; for example, if you heard an 'oo' sound as in 'hoot', you may answer with the word \"hoot\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mystery_1:\n",
    "\n",
    "mystery_2:\n",
    "\n",
    "mystery_3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will examine just one vowel in greater detail. \n",
    "Select one mystery vowel to analyze below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "### Modify the line below:\n",
    "text = ['SELECT_ONE_MYSTERY_VOWEL']\n",
    "\n",
    "speech = np.zeros(1)\n",
    "for t in text:\n",
    "    F = np.array(Fdict[t][0])\n",
    "    Fb = np.array(Fdict[t][1])\n",
    "    print(t)\n",
    "\n",
    "    vow,B,A = voca(ex,F,Fb)\n",
    "    speech = np.concatenate((speech,vow))\n",
    "\n",
    "speech = speech/np.std(speech)\n",
    "plt.plot(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the power spectral density (PSD)\n",
    "plt.psd(speech, 1024)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_order = 10\n",
    "s = speech\n",
    "\n",
    "a = librosa.core.lpc(s, order=lpc_order)\n",
    "print(a)\n",
    "s_hat = scipy.signal.lfilter([0] + -1*a[1:], [1], s)\n",
    "s_err = s[1:] - s_hat[:-1]\n",
    "plt.plot(s[1:])\n",
    "plt.plot(s_hat[:-1], linestyle='--')\n",
    "plt.legend(['y', 'y_hat'])\n",
    "plt.title('LP Model Forward Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s[1:101])\n",
    "plt.plot(s_hat[:100])\n",
    "plt.legend(['y', 'y_hat'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 (10 points)\n",
    "\n",
    "What is being visualized as y and y_hat on the above plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = si.freqz(b=1,a = a, fs=1)\n",
    "plt.plot(w,20*np.log10(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,p,k = si.tf2zpk(B,A)\n",
    "    \n",
    "unit_circle = patches.Circle((0,0), radius=1, fill=False, color='black', ls='solid', alpha=0.9)\n",
    "ax = plt.subplot(111)\n",
    "ax.add_patch(unit_circle)\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "r = 1.5; plt.axis('scaled'); plt.axis([-r, r, -r, r])\n",
    "ticks = [-1, -.5, .5, 1]; plt.xticks(ticks); plt.yticks(ticks)    \n",
    "    \n",
    "plt.plot(z.real, z.imag, 'ko', fillstyle='none', ms = 10)\n",
    "plt.plot(p.real, p.imag, 'kx', fillstyle='none', ms = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.abs(librosa.stft(s,n_fft=256,hop_length = 64))\n",
    "ld.specshow(librosa.amplitude_to_db(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 (20 points)\n",
    "\n",
    "Record yourself speaking the same vowel sound you analyzed above. \n",
    "Graph the power spectral density (PSD) of your recording alongside the PSD of the synthetic signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 (10 points)\n",
    "\n",
    "How does the power spectral density of your recorded signal compare to the LPC spectrum? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Singing Vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use a spoken sound to process an excitation that plays a melody. In music such an effect is known as vocoding and it is used to produce a talking musical instrument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_to_formants(lpc, sr):    \n",
    "    \"\"\"Convert LPC to formants    \n",
    "    \"\"\"\n",
    "        \n",
    "    # extract roots, get angle and radius\n",
    "    roots = np.roots(lpc)\n",
    "    \n",
    "    pos_roots = roots[np.imag(roots)>=0]\n",
    "    if len(pos_roots)<len(roots)//2:\n",
    "        pos_roots = list(pos_roots) + [0] * (len(roots)//2 - len(pos_roots))\n",
    "    if len(pos_roots)>len(roots)//2:\n",
    "        pos_roots = pos_roots[:len(roots)//2]\n",
    "    \n",
    "    w = np.angle(pos_roots)\n",
    "    a = np.abs(pos_roots)\n",
    "    \n",
    "    order = np.argsort(w)\n",
    "    w = w[order]\n",
    "    a = a[order]\n",
    "    \n",
    "    freqs = w * (sr/(2*np.pi))\n",
    "    bws =  -0.5 * (sr/(2*np.pi)) * np.log(a)    \n",
    "    \n",
    "    # exclude DC and sr/2 frequencies\n",
    "    return freqs, bws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questioon 5 [10 points] \n",
    "\n",
    "Record yourself speaking slowly the sentence \"Mister Blue Sky\". Plot a spectrogram of the speech sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 [30 points]\n",
    "\n",
    "In this question we will create a song based on the spoken sentence you recorded. You will choose the melody by creating a sequence of pitches that change slowly over time.\n",
    "Write a function that does the following:\n",
    "\n",
    "1. Divide the speech signal into short slices (frames) of 512 samples with 50% overlap\n",
    "2. For each speech segment compute formants by converting lpc_to_formants (F,Fb)\n",
    "3. Choose a pitch (f0) for each segment\n",
    "4. Using the voca function, create a speech sound (vow) from an excitation (ex) with that pitch\n",
    "4. Overlap and add the sound segments with cross-fade window to create one long sound file \n",
    "\n",
    "You are free to alter the durations of the segments and choice of notes for the melody. \n",
    "Note that the notes should be relatively long (f0 should not change very often).\n",
    "\n",
    "Cross-fade between segments can be done by applying a traingular (numpy.bartlett) or raised cosine (numpy.hanning) window to each segment before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the speech file\n",
    "sr, wave = wavfile.read(\"YOUR_SPEECH_MONO_WAV_FILE.wav\")\n",
    "\n",
    "# precompute the hamming window\n",
    "frame_len = 512\n",
    "window = scipy.signal.hann(frame_len)\n",
    "vocode = np.zeros(len(wave+frame_len))\n",
    "\n",
    "# 50% window steps for overlap-add\n",
    "for i in range(0,len(wave),frame_len//2):\n",
    "    wave_slice = wave[i:i+frame_len]\n",
    "        \n",
    "### Your Code Here\n",
    "\n",
    "    vow,B,A = voca(ex,F,Fb)\n",
    "    vocode[i:i+frame_len] += vow * window\n",
    "\n",
    "wavfile.write(\"YOUR_OUTPUT_FILE.wav\", sr, vocode[:len(wave)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 [10 points]\n",
    "\n",
    "Why did we use overlapping windows for vocoder? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` your response here ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
